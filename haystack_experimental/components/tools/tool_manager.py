import json
from typing import Any, Dict, List, Optional

from haystack import component, default_from_dict, default_to_dict, logging
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack.core.serialization import import_class_by_name
from haystack.dataclasses import ChatMessage
from haystack.lazy_imports import LazyImport
from haystack.utils import deserialize_secrets_inplace

from haystack_experimental.components.tools import Tool
from haystack_experimental.components.tools.openapi import LLMProvider
from haystack_experimental.util import serialize_secrets_inplace

with LazyImport("Run 'pip install anthropic-haystack'") as anthropic_import:
    # pylint: disable=import-error
    from haystack_integrations.components.generators.anthropic import AnthropicChatGenerator

with LazyImport("Run 'pip install cohere-haystack'") as cohere_import:
    # pylint: disable=import-error
    from haystack_integrations.components.generators.cohere import CohereChatGenerator

logger = logging.getLogger(__name__)


@component
class ToolManager:
    def __init__(
        self,
        tools: List[Dict[str, Any]],
        generator_api: LLMProvider,
        generator_api_params: Optional[Dict[str, Any]] = None,
    ):
        self.function_map = {}
        self.tools_definitions: List[Dict[str, Any]] = []

        for tool_config in tools:
            tool_class_name: str = tool_config.pop("type", "")
            if not tool_class_name:
                logger.warning(f"Tool type not specified in config: {tool_config}. Skipping this tool.")
                continue

            try:
                tool_class = import_class_by_name(tool_class_name)
                if not issubclass(tool_class, Tool):
                    logger.warning(f"{tool_class_name} is not a subclass of Tool. Skipping this tool.")
                    continue

                tool: Tool = tool_class(**tool_config)
                tool_definitions = tool.get_tools_definitions()
                for tool_def in tool_definitions:
                    self.function_map[tool_def["function"]["name"]] = tool
                self.tools_definitions.extend(tool_definitions)
                logger.info(f"Successfully initialized tool: {tool_class_name}")
            except Exception as e:
                logger.error(f"Failed to initialize tool {tool_class_name}. Error: {str(e)}")

        self.generator_api = generator_api
        self.generator_api_params = generator_api_params or {}
        self.chat_generator = self._init_generator(generator_api, self.generator_api_params)

    def _init_generator(self, generator_api: LLMProvider, generator_api_params: Dict[str, Any]):
        if generator_api == LLMProvider.OPENAI:
            return OpenAIChatGenerator(**generator_api_params)
        if generator_api == LLMProvider.COHERE:
            cohere_import.check()
            return CohereChatGenerator(**generator_api_params)
        if generator_api == LLMProvider.ANTHROPIC:
            anthropic_import.check()
            return AnthropicChatGenerator(**generator_api_params)
        raise ValueError(f"Unsupported generator API: {generator_api}")

    @component.output_types(service_response=List[ChatMessage])
    def run(
        self, messages: List[ChatMessage], fc_generator_kwargs: Optional[Dict[str, Any]] = None
    ) -> Dict[str, List[ChatMessage]]:
        """
        Invokes the underlying OpenAPI service/tool with the function calling payload generated by the chat generator.

        :param messages: List of ChatMessages to generate function calling payload (e.g. human instructions). The last
        message should be human instruction containing enough information to generate the function calling payload
        suitable for the OpenAPI service/tool used. See the examples in the class docstring.
        :param fc_generator_kwargs: Additional arguments for the function calling payload generation process.
        :returns: The response from the service after invoking the function.
        """
        fc_generator_kwargs = fc_generator_kwargs or {}
        fc_generator_kwargs["tools"] = self.tools_definitions

        fc_payload = self.chat_generator.run(messages, fc_generator_kwargs)
        try:
            invocation_payload = json.loads(fc_payload["replies"][0].content)
            function_name = invocation_payload[0].get("function", {}).get("name")
            if function_name not in self.function_map:
                raise ValueError(f"Unknown function: {function_name}")

            invoker = self.function_map[function_name]
            service_response = invoker.invoke(invocation_payload)
        except Exception as e:
            service_response = {"error": str(e)}

        response_messages = [ChatMessage.from_user(json.dumps(service_response))]
        return {"service_response": response_messages}

    def to_dict(self) -> Dict[str, Any]:
        """
        Serialize this component to a dictionary.

        :returns:
            The serialized component as a dictionary.
        """
        serialize_secrets_inplace(self.generator_api_params, keys=["api_key"], recursive=True)
        return default_to_dict(
            self,
            tools=[
                {"type": type(self.function_map[func_name]).__name__, **self.function_map[func_name].__dict__}
                for func_name in self.function_map
            ],
            generator_api=self.generator_api.value,
            generator_api_params=self.generator_api_params,
        )

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ToolManager":
        """
        Deserialize this component from a dictionary.

        :param data: The dictionary representation of this component.
        :returns:
            The deserialized component instance.
        """
        deserialize_secrets_inplace(data["init_parameters"], keys=["credentials"])
        deserialize_secrets_inplace(data["init_parameters"]["generator_api_params"], keys=["api_key"])
        init_params = data.get("init_parameters", {})
        generator_api = init_params.get("generator_api")
        data["init_parameters"]["generator_api"] = LLMProvider.from_str(generator_api)
        return default_from_dict(cls, data)
