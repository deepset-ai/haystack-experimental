from concurrent.futures import ThreadPoolExecutor
from typing import Any, List, Optional

from haystack import Document, component, default_from_dict, default_to_dict
from haystack.components.embedders.types.protocol import TextEmbedder
from haystack.core.serialization import component_to_dict
from haystack.utils.deserialization import deserialize_component_inplace

from haystack_experimental.components.retrievers.types import EmbeddingRetriever, KeywordRetriever


@component
class MultiQueryKeywordRetriever:
    """
    A component that retrieves documents using multiple queries in parallel with a keyword-based retriever.

    This component takes a list of text queries and uses a keyword-based retriever to find relevant documents for each
    query in parallel, using a thread pool to manage concurrent execution. The results are combined and sorted by
    relevance score.

    You can use this component in combination with QueryExpander component to enhance the retrieval process.

    ### Usage example
    ```python
    from haystack import Document
    from haystack.components.writers import DocumentWriter
    from haystack.document_stores.in_memory import InMemoryDocumentStore
    from haystack.document_stores.types import DuplicatePolicy
    from haystack.components.retrievers import InMemoryBM25Retriever
    from haystack_experimental.components.query import QueryExpander
    from haystack_experimental.components.retrievers.multi_query_retriever import MultiQueryKeywordRetriever

    documents = [
        Document(content="Renewable energy is energy that is collected from renewable resources."),
        Document(content="Solar energy is a type of green energy that is harnessed from the sun."),
        Document(content="Wind energy is another type of green energy that is generated by wind turbines."),
        Document(content="Hydropower is a form of renewable energy using the flow of water to generate electricity."),
        Document(content="Geothermal energy is heat that comes from the sub-surface of the earth.")
    ]

    document_store = InMemoryDocumentStore()
    doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)
    doc_writer.run(documents=documents)

    in_memory_retriever = InMemoryBM25Retriever(document_store=document_store)
    multiquery_retriever = MultiQueryKeywordRetriever(retriever=in_memory_retriever)
    results = multiquery_retriever.run(queries=["renewable energy?", "Geothermal", "Hydropower"])
    print(results["documents"])
    >>
    >> Document(id=..., content: 'Geothermal energy is heat that comes from the sub-surface of the earth.', score: 1.6474448833731097)
    >> Document(id=..., content: 'Renewable energy is energy that is collected from renewable resources.', score: 1.5255309812344944)
    >> Document(id=..., content: 'Hydropower is a form of renewable energy using the flow of water to generate electricity.', score: 1.1218095927314788)
    >> Document(id=..., content: 'Solar energy is a type of green energy that is harnessed from the sun.', score: 0.6769389901560819)
    ```
    """  # noqa E501

    def __init__(
        self,
        retriever: KeywordRetriever,
        top_k: int = 3,
        filters: Optional[dict[str, Any]] = None,
        max_workers: int = 3,
    ):
        """
        Initialize MultiQueryKeywordRetriever.

        :param retriever: The keyword-based retriever to use for document retrieval.
        :param top_k: Number of documents to retrieve per query. Default is 3.
        :param filters: Optional filters to apply to the retrieval.
        :param max_workers: Maximum number of worker threads for parallel processing. Default is 3.
        """
        self.retriever = retriever
        self.top_k = top_k
        self.filters = filters
        self.max_workers = max_workers

    @component.output_types(documents=list[Document])
    def run(
        self, queries: List[str], top_k: Optional[int] = None, filters: Optional[dict[str, Any]] = None
    ) -> dict[str, Any]:
        """
        Retrieve documents using multiple queries in parallel.

        :param queries: List of text queries to process.
        :param top_k: Number of documents to retrieve per query. If provided, overrides the top_k from initialization.
        :param filters: Optional filters to apply to the retrieval.
        :returns:
            A dictionary containing:
                `documents`: List of retrieved documents sorted by relevance score.
        """
        top_k_to_use = top_k if top_k is not None else self.top_k
        filters_to_use = filters if filters is not None else self.filters

        docs: list[Document] = []
        seen_contents = set()

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            queries_results = executor.map(
                lambda query: self._run_on_thread(query, top_k_to_use, filters_to_use), queries
            )
            for result in queries_results:
                if not result:
                    continue
                # deduplicate based on content
                for doc in result:
                    if doc.content not in seen_contents:
                        docs.append(doc)
                        seen_contents.add(doc.content)

        docs.sort(key=lambda x: x.score or 0.0, reverse=True)
        return {"documents": docs}

    def _run_on_thread(
        self, query: str, top_k: Optional[int], filters: Optional[dict[str, Any]]
    ) -> Optional[list[Document]]:
        """
        Process a single query on a separate thread.

        :param query: The text query to process.
        :param filters: Optional filters to apply to the retrieval.
        :returns:
            List of retrieved documents or None if no results.
        """
        result = self.retriever.run(query=query, top_k=top_k, filters=filters)
        if result and "documents" in result:
            return result["documents"]
        return None

    def to_dict(self) -> dict[str, Any]:
        """
        Serializes the component to a dictionary.

        :returns:
            The serialized component as a dictionary.
        """
        return default_to_dict(
            self,
            retriever=component_to_dict(obj=self.retriever, name="retriever"),
            top_k=self.top_k,
            filters=self.filters,
            max_workers=self.max_workers,
        )

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "MultiQueryKeywordRetriever":
        """
        Deserializes the component from a dictionary.

        :param data: The dictionary to deserialize from.
        :returns:
            The deserialized component.
        """
        deserialize_component_inplace(data["init_parameters"], key="document_embedder")
        return default_from_dict(cls, data)


@component
class MultiQueryEmbeddingRetriever:
    """
    A component that retrieves documents using multiple queries in parallel with an embedding-based retriever.

    This component takes a list of text queries, converts them to embeddings using a query embedder,
    and then uses an embedding-based retriever to find relevant documents for each query in parallel.
    The results are combined and sorted by relevance score.

    ### Usage example

    ```python
    from haystack.components.embedders import SentenceTransformersQueryEmbedder
    from haystack_experimental.components.retrievers import MultiQueryEmbeddingRetriever
    from haystack_integrations.components.retrievers.opensearch import OpenSearchEmbeddingRetriever

    query_embedder = SentenceTransformersQueryEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
    retriever = OpenSearchEmbeddingRetriever(document_store=document_store)

    multi_query_retriever = MultiQueryEmbeddingRetriever(
        retriever=retriever,
        query_embedder=query_embedder,
        top_k=5,
        max_workers=3
    )

    queries = ["What is machine learning?", "How does AI work?", "Explain neural networks"]
    result = multi_query_retriever.run(queries=queries)
    documents = result["documents"]
    ```
    """

    def __init__(
        self,
        *,
        retriever: EmbeddingRetriever,
        query_embedder: TextEmbedder,
        top_k: int = 3,
        filters: Optional[dict[str, Any]] = None,
        max_workers: int = 3,
    ):
        """
        Initialize MultiQueryEmbeddingRetriever.

        :param retriever: The embedding-based retriever to use for document retrieval.
        :param query_embedder: The query embedder to convert text queries to embeddings.
        :param top_k: Number of documents to retrieve per query.
        :param max_workers: Maximum number of worker threads for parallel processing.
        """
        self.retriever = retriever
        self.query_embedder = query_embedder
        self.top_k = top_k
        self.filters = filters
        self.max_workers = max_workers
        if hasattr(self.query_embedder, "warm_up") and callable(getattr(self.query_embedder, "warm_up")):
            self.query_embedder.warm_up()

    @component.output_types(documents=List[Document])
    def run(
        self, queries: List[str], top_k: Optional[int] = None, filters: Optional[dict[str, Any]] = None
    ) -> dict[str, Any]:
        """
        Retrieve documents using multiple queries in parallel.

        :param queries: List of text queries to process.
        :param top_k: Number of documents to retrieve per query. If provided, overrides the instance top_k.
        :param filters: Optional filters to apply to the retrieval.
        :returns:
            A dictionary containing:
                - `documents`: List of retrieved documents sorted by relevance score.
        """
        top_k_to_use = top_k if top_k is not None else self.top_k
        filters_to_use = filters if filters is not None else self.filters

        docs = []
        seen_contents = set()
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            queries_results = executor.map(
                lambda query: self._run_on_thread(query, top_k_to_use, filters_to_use), queries
            )
            for result in queries_results:
                if not result:
                    continue
                for doc in result:
                    # deduplicate based on content
                    if doc.content not in seen_contents:
                        docs.append(doc)
                        seen_contents.add(doc.content)

        docs.sort(key=lambda x: x.score or 0.0, reverse=True)
        return {"documents": docs}

    def _run_on_thread(self, query: str, top_k: int, filters: Optional[dict[str, Any]]) -> Optional[List[Document]]:
        """
        Process a single query on a separate thread.

        :param query: The text query to process.
        :param filters: Optional filters to apply to the retrieval.
        :returns:
            List of retrieved documents or None if no results.
        """
        embedding_result = self.query_embedder.run(text=query)
        query_embedding = embedding_result["embedding"]
        result = self.retriever.run(query_embedding=query_embedding, filters=filters, top_k=top_k)
        if result and "documents" in result:
            return result["documents"]
        return None

    def to_dict(self) -> dict[str, Any]:
        """
        Serializes the component to a dictionary.

        :returns:
            A dictionary representing the serialized component.
        """
        return default_to_dict(
            self,
            retriever=component_to_dict(obj=self.retriever, name="retriever"),
            query_embedder=component_to_dict(obj=self.query_embedder, name="query_embedder"),
            top_k=self.top_k,
            filters=self.filters,
            max_workers=self.max_workers,
        )

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "MultiQueryEmbeddingRetriever":
        """
        Deserializes the component from a dictionary.

        :param data: The dictionary to deserialize from.
        :returns:
            The deserialized component.
        """
        deserialize_component_inplace(data["init_parameters"], key="retriever")
        deserialize_component_inplace(data["init_parameters"], key="query_embedder")
        return default_from_dict(cls, data)
