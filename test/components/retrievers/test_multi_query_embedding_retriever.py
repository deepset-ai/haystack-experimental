# SPDX-FileCopyrightText: 2022-present deepset GmbH <info@deepset.ai>
#
# SPDX-License-Identifier: Apache-2.0
import os

import pytest
from haystack import Document, Pipeline
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.embedders.sentence_transformers_document_embedder import SentenceTransformersDocumentEmbedder
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack.components.retrievers import InMemoryEmbeddingRetriever
from haystack.components.writers import DocumentWriter
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.document_stores.types import DuplicatePolicy
from haystack_experimental.components.query import QueryExpander

from haystack_experimental.components.retrievers.multi_query_embedding_retriever import MultiQueryEmbeddingRetriever

class TestMultiQueryEmbeddingRetriever:

    @pytest.fixture
    def sample_documents(self):
        return [
            Document(content="Renewable energy is energy that is collected from renewable resources.", meta={"category": None}),
            Document(content="Solar energy is a type of green energy that is harnessed from the sun.", meta={"category": "solar"}),
            Document(content="Wind energy is another type of green energy that is generated by wind turbines", meta={"category": "wind"}),
            Document(content="Hydropower is a form of renewable energy using the flow of water to generate electricity.", meta={"category": "hydro"}),
            Document(content="Geothermal energy is heat that comes from the sub-surface of the earth.", meta={"category": "geo"}),
            Document(content="Fossil fuels, such as coal, oil, and natural gas, are non-renewable energy sources.", meta={"category": "fossil"}),
            Document(content="Nuclear energy is produced through nuclear reactions, typically using uranium or plutonium as fuel.", meta={"category": "nuclear"}),
        ]

    @pytest.fixture
    def document_store_with_embeddings(self, sample_documents):
        """Create a document store populated with embedded documents."""
        document_store = InMemoryDocumentStore()
        doc_embedder = SentenceTransformersDocumentEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        doc_embedder.warm_up()
        doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)
        
        embedded_docs = doc_embedder.run(sample_documents)["documents"]
        doc_writer.run(documents=embedded_docs)
        return document_store

    def test_init_with_default_parameters(self):

        embedding_retriever = InMemoryEmbeddingRetriever(document_store=InMemoryDocumentStore())
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")

        retriever = MultiQueryEmbeddingRetriever(retriever=embedding_retriever, query_embedder=query_embedder)
        
        assert retriever.retriever == embedding_retriever
        assert retriever.query_embedder == query_embedder
        assert retriever.top_k == 3
        assert retriever.filters is None
        assert retriever.max_workers == 3

    def test_init_with_custom_parameters(self, document_store_with_embeddings):
        filters = {"category": "energy"}
        embedding_retriever = InMemoryEmbeddingRetriever(document_store=InMemoryDocumentStore())
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")

        retriever = MultiQueryEmbeddingRetriever(
            retriever=embedding_retriever,
            query_embedder=query_embedder,
            top_k=5,
            filters=filters,
            max_workers=2
        )
        
        assert retriever.retriever == embedding_retriever
        assert retriever.query_embedder == query_embedder
        assert retriever.top_k == 5
        assert retriever.filters == filters
        assert retriever.max_workers == 2

    def test_run_with_multiple_queries(self, document_store_with_embeddings):
        """Test running with multiple queries."""
        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever,
            query_embedder=query_embedder,
            top_k=2
        )
        
        queries = ["renewable energy", "solar power", "wind turbines"]
        result = multi_retriever.run(queries=queries)
        
        assert "documents" in result
        assert len(result["documents"]) > 0
        assert all(isinstance(doc, Document) for doc in result["documents"])
        # Documents should be sorted by score (highest first)
        scores = [doc.score for doc in result["documents"] if doc.score is not None]
        assert scores == sorted(scores, reverse=True)

    def test_run_with_deduplication(self, document_store_with_embeddings):
        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever,
            query_embedder=query_embedder,
            top_k=3
        )
        
        # Use queries that might return the same documents
        queries = ["renewable energy", "green energy", "sustainable energy"]
        result = multi_retriever.run(queries=queries)
        
        assert "documents" in result
        # Check that no duplicate content exists
        contents = [doc.content for doc in result["documents"]]
        assert len(contents) == len(set(contents))

    def test_run_with_custom_top_k(self, document_store_with_embeddings):
        """Test running with custom top_k parameter."""
        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever,
            query_embedder=query_embedder,
            top_k=1
        )
        
        result = multi_retriever.run(queries=["energy"], top_k=5)
        
        assert "documents" in result
        # Should respect the custom top_k from run method
        assert len(result["documents"]) <= 5

    def test_run_with_filters(self, document_store_with_embeddings):
        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        filters = {"field": "category", "operator": "==", "value": "solar"}
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever,
            query_embedder=query_embedder,
            filters=filters
        )
        
        result = multi_retriever.run(queries=["energy"])
        assert "documents" in result
        assert all(doc.meta.get("category") == "solar" for doc in result["documents"])

    """"
    def test_run_with_empty_queries(self, mock_retriever, mock_query_embedder):
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=mock_retriever,
            query_embedder=mock_query_embedder
        )
        
        result = multi_retriever.run(queries=[])
        
        assert "documents" in result
        assert result["documents"] == []
    """

    """
    def test_run_with_missing_documents_key(self, mock_retriever, mock_query_embedder):
        
        mock_query_embedder.run.return_value = {"embedding": [0.1, 0.2, 0.3]}
        mock_retriever.run.return_value = {"other_key": "value"}
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=mock_retriever,
            query_embedder=mock_query_embedder
        )
        
        result = multi_retriever.run(queries=["query"])
        
        assert "documents" in result
        assert result["documents"] == []
    """
    def test_parallel_execution(self, document_store_with_embeddings):

        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever,
            query_embedder=query_embedder,
            max_workers=2
        )
        
        queries = ["renewable energy", "solar power", "wind energy", "geothermal"]
        result = multi_retriever.run(queries=queries)
        
        assert "documents" in result
        assert len(result["documents"]) > 0

    def test_to_dict(self, document_store_with_embeddings):
        multi_retriever = MultiQueryEmbeddingRetriever(
            retriever=InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings),
            query_embedder=SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2"),
            top_k=5,
            filters = {"field": "category", "operator": "==", "value": "solar"},
            max_workers=2
        )
        
        result = multi_retriever.to_dict()
        
        assert "type" in result
        assert "init_parameters" in result
        assert result["init_parameters"]["top_k"] == 5
        assert result["init_parameters"]["filters"] == {"field": "category", "operator": "==", "value": "solar"}
        assert result["init_parameters"]["max_workers"] == 2
        assert "retriever" in result["init_parameters"]
        assert "query_embedder" in result["init_parameters"]

    def test_from_dict(self):
        data = {
            'type': 'haystack_experimental.components.retrievers.multi_query_embedding_retriever.MultiQueryEmbeddingRetriever',
            'init_parameters': {
                'retriever': {
                    'type': 'haystack.components.retrievers.in_memory.embedding_retriever.InMemoryEmbeddingRetriever',
                    'init_parameters': {
                        'document_store': {
                            'type': 'haystack.document_stores.in_memory.document_store.InMemoryDocumentStore',
                            'init_parameters': {
                                'bm25_tokenization_regex': '(?u)\\b\\w\\w+\\b',
                                'bm25_algorithm': 'BM25L',
                                'bm25_parameters': {},
                                'embedding_similarity_function': 'dot_product',
                                'index': '4bb5369d-779f-487b-9c16-3c40f503438b',
                                # 'return_embedding': True  # ToDo: investigate why this fails
                            }
                        },
                        'filters': None,
                        'top_k': 10,
                        'scale_score': False,
                        'return_embedding': False,
                        'filter_policy': 'replace'}
                },
                'query_embedder': {
                    'type': 'haystack.components.embedders.sentence_transformers_text_embedder.SentenceTransformersTextEmbedder',
                    'init_parameters': {
                        'model': 'sentence-transformers/all-MiniLM-L6-v2',
                        'token': {'type': 'env_var', 'env_vars': ['HF_API_TOKEN', 'HF_TOKEN'], 'strict': False},
                        'prefix': '',
                        'suffix': '',
                        'batch_size': 32,
                        'progress_bar': True,
                        'normalize_embeddings': False,
                        'trust_remote_code': False,
                        'local_files_only': False,
                        'truncate_dim': None,
                        'model_kwargs': None,
                        'tokenizer_kwargs': None,
                        'config_kwargs': None,
                        'precision': 'float32',
                        'encode_kwargs': None,
                        'backend': 'torch'
                    }
                },
                'top_k': 5,
                'filters': {'field': 'category', 'operator': '==', 'value': 'solar'},
                'max_workers': 2}
        }
            
        result = MultiQueryEmbeddingRetriever.from_dict(data)

        assert isinstance(result, MultiQueryEmbeddingRetriever)
        assert result.top_k == 5
        assert result.filters == {'field': 'category', 'operator': '==', 'value': 'solar'}
        assert result.max_workers == 2

    @pytest.mark.skipif(
        not os.environ.get("OPENAI_API_KEY", None),
        reason="Export an env var called OPENAI_API_KEY containing the OpenAI API key to run this test.",
    )
    @pytest.mark.integration
    def test_pipeline_integration(self, document_store_with_embeddings):
        expander = QueryExpander(
            chat_generator=OpenAIChatGenerator(model="gpt-4.1-mini"), n_expansions=3, include_original_query=True
        )
        in_memory_retriever = InMemoryEmbeddingRetriever(document_store=document_store_with_embeddings)
        query_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
        multiquery_retriever = MultiQueryEmbeddingRetriever(
            retriever=in_memory_retriever, query_embedder=query_embedder
        )

        pipeline = Pipeline()
        pipeline.add_component("query_expander", expander)
        pipeline.add_component("multiquery_retriever", multiquery_retriever)
        pipeline.connect("query_expander.queries", "multiquery_retriever.queries")

        data = {"query_expander" : {"query": "green energy sources"}}
        results = pipeline.run(data=data, include_outputs_from={"query_expander", "multiquery_retriever"})

        assert "multiquery_retriever" in results
        assert "documents" in results["multiquery_retriever"]
        assert len(results["multiquery_retriever"]["documents"]) > 0
        assert "query_expander" in results
        assert "queries" in results["query_expander"]
        assert len(results["query_expander"]["queries"]) == 4
