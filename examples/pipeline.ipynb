{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHJLbDvNWSSy"
   },
   "outputs": [],
   "source": [
    "!pip install haystack-ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnJ1NIDRWNHl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "from haystack_experimental import Pipeline\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "\n",
    "prompt_builder = ChatPromptBuilder()\n",
    "llm = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipe.add_component(\"llm\", llm)\n",
    "pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "location = \"Berlin\"\n",
    "messages = [ChatMessage.from_system(\"Always respond in English even if some input data is in other languages and be brief.\"),\n",
    "            ChatMessage.from_user(\"Erzähl mir etwas über {{location}}\")]\n",
    "pipe.run(data={\"prompt_builder\": {\"template_variables\":{\"location\": location}, \"template\": messages}})\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
